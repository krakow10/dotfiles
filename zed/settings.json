// Zed settings
//
// For information on how to configure Zed, see the Zed
// documentation: https://zed.dev/docs/configuring-zed
//
// To see all of Zed's default settings without changing your
// custom settings, run the `open default settings` command
// from the command palette or from `Zed` application menu.
{
  "show_edit_predictions": false,
  "ssh_connections": [],
  "agent": {
    "inline_assistant_model": {
      "provider": "ollama",
      "model": "gpt-oss:latest"
    },
    "default_profile": "write",
    "profiles": {
      "test": {
        "name": "test",
        "tools": {
                    "terminal": true,
                    "copy_path": true,
                    "create_directory": true,
                    "delete_path": true,
                    "diagnostics": true,
                    "edit_file": true,
                    "fetch": true,
                    "find_path": true,
                    "grep": true,
                    "list_directory": true,
                    "move_path": true,
                    "now": true,
                    "open": true,
                    "read_file": true,
                    "thinking": true
                },
        "enable_all_context_servers": false,
        "context_servers": {}
      }
    },
    "default_model": {
      "provider": "llama.cpp",
      "model": "gpt-oss"
    },
  },
  "theme": "Mariana",
  "features": {
    "copilot": false
  },
  "base_keymap": "SublimeText",
  "hide_mouse": "never",
  "multi_cursor_modifier": "cmd_or_ctrl",
  "ui_font_size": 14,
  "buffer_font_size": 12.0,
  "buffer_font_family": "MartianMono Nerd Font",
  "hard_tabs": true,
  "tab_size": 4,
  "format_on_save": "off",

  "file_types": {
      "Luau": ["lua"]
  },

  "lsp": {
    "luau-lsp": {
          "settings": {
              "luau-lsp": {},
              "ext": {
                  "roblox": {
                      "enabled": true,
                      "security_level": "roblox_script"
                  }
              }
          }
      }
  },
  "language_models": {
    "openai_compatible": {
      "llama.cpp": {
        "api_url": "http://localhost:8080",
        "available_models": [
          {
            "max_tokens": 32768,
            "name": "gpt-oss"
          }
        ]
      }
    }
  }
}
